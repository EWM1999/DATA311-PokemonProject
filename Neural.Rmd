---
title: "Neural networks, Pokemon"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
data = read.csv("pokemon_alopez247.csv", header=T)
```

#Neural Networks
```{r}
library(nnet)
library(NeuralNetTools)
library(neuralnet)
set.seed(53747958)
numeric_col <- c(5:12, 16, 20:21)
pokemon[,numeric_col] <- scale(pokemon[,numeric_col])
set.seed(1995)
train<-sample(1:nrow(pokemon),505)
testset<-poke[-train,]
trainset<-poke[train,]
```

```{r}
library(gclus)
library(nnet)
library(NeuralNetTools)
set.seed(1995)
spoke <- cbind(scale(trainset[,6:11]), factor(trainset$isLegendary))
colnames(spoke)[7] <- "isLegendary"
spoke<-data.frame(spoke)
nnpoke <- nnet(factor(isLegendary)~., data=spoke, size=9)
table(trainset$isLegendary, predict(nnpoke, type="class"))
plotnet(nnpoke)
```

```{r}
spoke
```

```{r}
spoketest <- cbind(scale(testset[,6:11]), factor(testset$isLegendary))
colnames(spoketest)[7] <- "isLegendary"
spoketest<-data.frame(spoketest)
table(spoketest$isLegendary, predict(nnpoke, newdata=spoketest, type="class"))
```

```{r}
attach(data)
trainsetg<-trainset[which(hasGender=='True'),]
testsetg<-testset[which(hasGender=='True'),]
trainsetg<-na.omit(trainsetg)
trainsetg
testsetg<-na.omit(testsetg)
testsetg
```

#Neural Net predicting Pr_Male
```{r}
set.seed(906534)
library(neuralnet)
nnmale <- neuralnet(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg, hidden=3, threshold=0.01)
plotnet(nnmale)
mse<-mean((compute(nnmale, testsetg[,6:11])$net.result-testsetg$Pr_Male)^2)
mse
```

Optimizing number of nodes in first layer
```{r}
for(i in 1:5){
  nnmaletr <- neuralnet(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg, hidden=c(i,3), threshold=0.01)
  print(paste("Number of hidden layer variables in first layer:", i))
  print(paste("MSE: ", mean((compute(nnmaletr, testsetg[,6:11])$net.result-testsetg$Pr_Male)^2)))
}
```

Optimizing number of nodes in second layer
```{r}
for(i in 1:5){
  nnmaletr <- neuralnet(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg, hidden=c(4,i), threshold=0.01)
  print(paste("Number of hidden layer variables in second layer:", i))
  print(paste("MSE: ", mean((compute(nnmaletr, testsetg[,6:11])$net.result-testsetg$Pr_Male)^2)))
}
```
MSE with 2 hidden layers and 4 and 3 nodes: 0.04011755
MSE with 1 hidden layer and 3 nodes: 0.03988659

```{r}
linmod<-lm(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg)
mean((predict(linmod,newdata=testsetg)-testsetg$Pr_Male)^2)
```
This is pretty close to our neural net modeled above when we use 1 hidden layer and 3 nodes. 


#Neural Net, predicting Generation
```{r}
set.seed(23453)
library(neuralnet)
trainsetg<-trainset[which(hasGender=='True'),]
testsetg<-testset[which(hasGender=='True'),]
trainsetg<-na.omit(trainsetg)
testsetg<-na.omit(testsetg)
nnGen <- neuralnet(Generation ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed + Pr_Male,data=trainsetg, hidden=4, threshold=0.01)
plotnet(nnGen)
mse<-mean((compute(nnGen, testsetg[,c(6:11, 16)])$net.result-testsetg$Generation)^2)
mse
```

@Barret, I cannot seem to get a misclassification table working for Generation, let me know if you can for whatever reason

```{r}
linmod<-lm(Generation ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg)
mean((predict(linmod,newdata=testsetg)-testsetg$Generation)^2)
```
