---
title: "Project"
author: "Emily Medema"
date: '2019-03-06'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Project: Pokemon Dataset

```{r}
pokemon<-read.csv("pokemon_alopez247.csv")
#plot(pokemon)
#plot(pokemon$Name~pokemon$Type_1)
#plot(pokemon$Name~. , data = pokemon, col = "blueviolet")
#look at all those tasty graphs
summary(pokemon)

```

Let's get some insight into the data in general. For example, lets look at a graph of the number of pokemon per type.

```{r}
library(ggplot2)
type<-ggplot(pokemon, aes(pokemon$Type_1, fill = pokemon$Type_1)) + geom_histogram(stat="count", color = "black") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
type
```

Before we get too far along, let's split up the data into training and testing sets
```{r}
#n <- nrow(pokemon)
#shuffled_df <- pokemon[sample(n), ]
#train_indices <- 1:round(0.6 * n)
#train <- shuffled_df[train_indices, ]
#test_indices <- (round(0.6 * n) + 1):n
#test <- shuffled_df[test_indices, ]
set.seed(1995)
train<-sample(1:nrow(pokemon),432)
poke.test<-pokemon[-train,]
poke.train<-pokemon[train,]

```

Let's try fitting a linear model with the response variable total and predictors HP, Attack, and Defense.

```{r}
library(DAAG)
linmod <- lm(poke.train$Total~poke.train$HP+poke.train$Attack+poke.train$Defense)
summary(linmod)
#plot(linmod)
plot(poke.train$HP+poke.train$Attack+poke.train$Defense, poke.train$Total)
abline(linmod, h = 0.5, col = "red")
#mmmm tasty sig values
predicted<-predict(linmod, newdata=poke.test)
mean(linmod$residuals^2)
mean((poke.test$Total-predicted)^2)
```


First attempt at Clustering
```{r}
eucdist<-dist(pokemon, method="euclidean")
mandist<-dist(pokemon, method = "manhattan")
clusPokemon<-hclust(eucdist, method = "single")
clusPokemon2<-hclust(mandist, method = "single")
plot(clusPokemon)
plot(clusPokemon2)
clusPokemonAvg<-hclust(eucdist, method = "average")
clusPokemonAvg2<-hclust(mandist, method = "average")
plot(clusPokemonAvg)
plot(clusPokemonAvg2)
clusComplete<-hclust(eucdist, method = "complete")
clusComplete2<-hclust(mandist, method = "complete")
plot(clusComplete)
plot(clusComplete2)

mancom <- cutree(clusComplete2, 2)
euccom<-cutree(clusComplete, 2)
manavg <- cutree(clusPokemonAvg2, 2)
eucavg<-cutree(clusPokemonAvg, 2)
table(mancom, euccom)
table(manavg, eucavg)
table(manavg, mancom)
table(euccom, eucavg)
```

@Barrett

See what a regression tree looks like using total as the predictor and hp, attack, defense, sp_atk, sp_def, and speed as predictors.
```{r}
library(tree)
poke<-data.frame(pokemon)
attach(poke)
pocl<-tree(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke)
plot(pocl)
text(pocl)
```

Now let's try pruning it back

```{r}
cv.pocl<-cv.tree(pocl, FUN=prune.tree)
plot(cv.pocl,type="b")
p.pocl<-prune.tree(pocl,best=10)
plot(p.pocl)
text(p.pocl)
summary(p.pocl)
```

Looks like pruning was unnecessary since the lowest MSE is with 12 nodes...

How about with bagging...

```{r}
library(randomForest)
set.seed(1995)
pokebag<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=6,importance=FALSE)
pokebag
pokebag2<-randomForest(isLegendary~ Total+hasGender,data=poke.train,mtry=6,importance=FALSE)
pokebag2
```
Random forest where m=3
```{r}
pokeRF<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=3,importance=TRUE)
pokeRF
pokeRF2<-randomForest(isLegendary~Total+hasGender,data=poke.train,mtry=3,importance=TRUE)
pokeRF2
```



Now, let's try to predict if a pokemon is legendary. I would assume that pokemon with a high total are legendary and after taking a peek at the data, it looks like most legendary pokemon do not have a gender. Let's see if this holds true in general.

```{r}
#https://www.kaggle.com/excaliburzero/predicting-legendary-pokemon
maxTotal<-order(pokemon$Total, decreasing = TRUE)
head(pokemon[maxTotal,])
```

This looks like if we have a high total the pokemon is most likely legendary. Let's graph it to see if it holds true

```{r}
library(ggplot2)
plot<-ggplot(pokemon, aes(x =Total, fill = isLegendary)) + geom_histogram()
plot
```

From this graph we can see that the higher the total the more likely a pokemon is to be legendary. In fact, it appears that a pokemon is only legendary when it is above 650 in total and most likely legendary from around 550-625

Now let's look at gender correlation

```{r}
pokemon$hasGender<-factor(pokemon$hasGender)
plot2<-ggplot(pokemon, aes(x =hasGender, fill = isLegendary)) + geom_bar()
plot2
```

This plot shows that most legendary pokemon do not have a gender.

Let see if there are any linear relations we can tease out. Name and number should have no effect on the data so I will exclude them from the start.

Kmeans


```{r}
library(mclust)
library(cluster)
library(dplyr)
library(fpc)
pokeNum<-select_if(pokemon, is.numeric)
distPoke<-daisy(pokemon)
#distPoke<-daisy(pokeNum)
summary(distPoke)
pokeDist<-cmdscale(distPoke)
plot(pokeDist, type = "n")
text(pokeDist, rownames(pokeDist))
set.seed(413)
#kAnimals<-kmeans(dAnimals, 3)
#plot(dAnimals, col = kAnimals$cluster)
#points(kAnimals$centers, col = 1:3, pch=8, cex=2)

clustore<-matrix(0, nrow = 721, ncol=25)
wsstore<-NULL
for(i in 1:10){
  km<-kmeans(pokeDist, i, nstart=10)
  clustore[,i]<-km$cluster
  wsstore[i]<-km$tot.withinss
}
plot(wsstore)

kPoke2<-kmeans(pokeDist, 7, nstart=25)
plot(pokeDist, col = kPoke2$cluster)
points(kPoke2$centers, col = 1:4, pch=8, cex=2)
#kAnimals$cluster
#table(rownames(pokemon), kPoke2$cluster)
out <- cbind(pokemon, clusterNum = kPoke2$cluster)
clusterGroups<-order(out$clusterNum, decreasing = TRUE)
head(out[clusterGroups,])

```

KNN classification

```{r}
library(class)
knnrun<-knn.cv(pokeDist, cl = poke.train$isLegendary, k = 5, prob = TRUE)
table(poke.train$isLegendary, knnrun)
```


Let's try analyzing via LDA

```{r}
library(MASS)
library(MLmetrics)
poke.train$hasGender<-factor(poke.train$hasGender)
poke.train$isLegendary<-factor(poke.train$isLegendary)
pokelda<-lda(poke.train$isLegendary~poke.train$hasGender+poke.train$Total)
table(poke.train$isLegendary, predict(pokelda)$class)
Sensitivity(poke.train$isLegendary, predict(pokelda)$class)
Recall(poke.train$isLegendary, predict(pokelda)$class) #same as sensitivity
Precision(poke.train$isLegendary, predict(pokelda)$class)
Specificity(poke.train$isLegendary, predict(pokelda)$class)
F1_Score(poke.train$isLegendary, predict(pokelda)$class)
```

Now let's try qda

```{r}

pokeqda<-qda(poke.train$isLegendary~poke.train$hasGender+poke.train$Total)
table(poke.train$isLegendary, predict(pokeqda)$class)
Sensitivity(poke.train$isLegendary, predict(pokelda)$class)
Recall(poke.train$isLegendary, predict(pokeqda)$class) #same as sensitivity
Precision(poke.train$isLegendary, predict(pokeqda)$class)
Specificity(poke.train$isLegendary, predict(pokeqda)$class)
F1_Score(poke.train$isLegendary, predict(pokeqda)$class)
```

Now lets try logistic regression

```{r}
simlog<-glm(factor(poke.train$isLegendary)~poke.train$hasGender+poke.train$Total, family = "binomial")
table(predict(simlog, type = "response")>0.5, poke.train$isLegendary)
```


I'm going to see how many legendary pokemon there are per generation and per type. As a refresher here is the number of pokemon per type in this dataset
```{r}
library(ggplot2)
type<-ggplot(pokemon, aes(pokemon$Type_1, fill = pokemon$Type_1)) + geom_histogram(stat="count", color = "black") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
type
```

```{r}
library(wesanderson)
#https://www.kaggle.com/excaliburzero/predicting-legendary-pokemon
poke<-data.frame(pokemon)
pokeLegend<-poke[which(isLegendary=='True'),]
plot(Generation~isLegendary)
TheLegends<-as.data.frame(table(pokeLegend$Generation))
colnames(TheLegends)<-c("Generation", "Legends")
TheLegends
summary(TheLegends)
plot<-ggplot(TheLegends, aes(Generation, Legends))+geom_bar(stat="identity")
plot
#color=scale_fill_manual(values=wes_palette("FantasticFox1"))
TheMan<-as.data.frame(table(pokeLegend$Type_1))
colnames(TheMan)<-c("Type 1", "Legends")
TheMan
summary(TheMan)
plot(TheMan)
maxTotalL<-order(TheMan$Legends, decreasing = TRUE)
head(TheMan[maxTotalL,])

#Of Type 2
TheMyth<-as.data.frame(table(pokeLegend$Type_2))
colnames(TheMyth)<-c("Type 2", "Legends")
TheMyth
summary(TheMyth)
plot(TheMyth)
maxTotalL2<-order(TheMyth$Legends, decreasing = TRUE)
head(TheMyth[maxTotalL2,])
```


Thanks to @Barret we can now subset the data

```{r}
poke<-data.frame(pokemon)
poke1<-poke[which(hasGender=='True'),]
attach(poke)
head(poke1)
```

Let's see if there is a relationship between score and gender

```{r}
set.seed(983457)
pokeG<-tree(Pr_Male~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed + Total,data=poke1)
plot(pokeG)
text(pokeG, pretty=0)
cv.pokeG<-cv.tree(pokeG, FUN=prune.tree)
plot(cv.pokeG)
prunePokeG<-prune.tree(pokeG, best=12)
plot(prunePokeG)
text(prunePokeG, pretty=0)
```


