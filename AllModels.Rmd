---
title: "DATA 311, All models"
author: "Barret Jackson, Emily Medema, Kathryn Lecha, Lauren St. Clair"
date: "April 3rd, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
``` 

```{r}
pokemon<-read.csv("pokemon_alopez247.csv")
```


Pokemon dataset split into training and testing sets
```{r}
set.seed(1995)
train<-sample(1:nrow(pokemon),432)
poke.test<-pokemon[-train,]
poke.train<-pokemon[train,]
```


#Clustering
Single, Average, and Complete linkage respectively modeled below  
```{r}
eucdist<-dist(pokemon, method="euclidean")
mandist<-dist(pokemon, method = "manhattan")
clusPokemon<-hclust(eucdist, method = "single")
clusPokemon2<-hclust(mandist, method = "single")
plot(clusPokemon)
plot(clusPokemon2)
clusPokemonAvg<-hclust(eucdist, method = "average")
clusPokemonAvg2<-hclust(mandist, method = "average")
plot(clusPokemonAvg)
plot(clusPokemonAvg2)
clusComplete<-hclust(eucdist, method = "complete")
clusComplete2<-hclust(mandist, method = "complete")
plot(clusComplete)
plot(clusComplete2)
mancom <- cutree(clusComplete2, 2)
euccom<-cutree(clusComplete, 2)
manavg <- cutree(clusPokemonAvg2, 2)
eucavg<-cutree(clusPokemonAvg, 2)
table(mancom, euccom)
table(manavg, eucavg)
table(manavg, mancom)
table(euccom, eucavg)
```
We see that a complete linkage method appears to fit our dataset best. 

K-Means might do better.

#K-Means
```{r}
library(mclust)
library(cluster)
library(dplyr)
library(fpc)
pokeNum<-select_if(pokemon, is.numeric)
distPoke<-daisy(pokemon)
#distPoke<-daisy(pokeNum)
summary(distPoke)
pokeDist<-cmdscale(distPoke)
plot(pokeDist, type = "n")
text(pokeDist, rownames(pokeDist))
set.seed(413)
clustore<-matrix(0, nrow = 721, ncol=25)
wsstore<-NULL
for(i in 1:10){
  km<-kmeans(pokeDist, i, nstart=10)
  clustore[,i]<-km$cluster
  wsstore[i]<-km$tot.withinss
}
plot(wsstore)
kPoke2<-kmeans(pokeDist, 7, nstart=25)
plot(pokeDist, col = kPoke2$cluster)
points(kPoke2$centers, col = 1:4, pch=8, cex=2)
out <- cbind(pokemon, clusterNum = kPoke2$cluster)
clusterGroups<-order(out$clusterNum, decreasing = TRUE)
head(out[clusterGroups,])
```

#K-Means 2 WHO WILL WIN
```{r}
library(mclust)
library(cluster)
library(dplyr)
library(fpc)
pokeNum<-select_if(pokemon, is.numeric)
distPoke<-daisy(pokemon)
summary(distPoke)
pokeDist<-cmdscale(distPoke)
plot(pokeDist, type = "n")
text(pokeDist, rownames(pokeDist))
set.seed(413)
clustore<-matrix(0, nrow = 721, ncol=25)
wsstore<-NULL
for(i in 1:10){
  km<-kmeans(pokeDist, i, nstart=10)
  clustore[,i]<-km$cluster
  wsstore[i]<-km$tot.withinss
}
plot(wsstore)
kPoke2<-kmeans(pokeDist, 7, nstart=25)
plot(pokeDist, col = kPoke2$cluster)
points(kPoke2$centers, col = 1:4, pch=8, cex=2)
out <- cbind(pokemon, clusterNum = kPoke2$cluster)
clusterGroups<-order(out$clusterNum, decreasing = TRUE)
out[clusterGroups,]
```

Ok, let's check out the mean for Total for each cluster

```{r}
for(i in 1:7) {
  print(paste("Mean for total for cluster ",i))
  print(mean(out[which(out$clusterNum==i),]$Total))
}
```

Ok, how about the number of isLegendary in each cluster

```{r}
for(i in 1:7) {
  print(paste("Number of isLegendary for cluster ",i))
  legendTemp<-out[which(out$clusterNum==i),]
  print(count(legendTemp,vars=isLegendary))
}
```

Ok, that didnt' look great, but it looks like isLegendary==TRUE are mostly in clusters 2 and 4.

#Number of Pokemon per Type 
```{r}
library(ggplot2)
type<-ggplot(pokemon, aes(pokemon$Type_1, fill = pokemon$Type_1)) + geom_histogram(stat="count", color = "black") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
type
```


#isLegendary Analyses

Let's see if we can predict if a Pokemon is legendary using the Total predictor. In using the predictor Total, we are under the assumption that legendary Pokemon have high totals. From looking at the data set this appears to be true. It also appears from the data set that legendary Pokemon do not have a gender except for a couple outliers. Let's see if this is the case,
```{r}
#https://www.kaggle.com/excaliburzero/predicting-legendary-pokemon
maxTotal<-order(pokemon$Total, decreasing = TRUE)
head(pokemon[maxTotal,])
```
It does appear that the Pokemon with the highest total are in fact of the legendary type. 

```{r}
library(ggplot2)
plot<-ggplot(pokemon, aes(x =Total, fill = isLegendary)) + geom_histogram()
plot
```
From this graph we can see that the higher the total the more likely a pokemon is to be legendary. In fact, it appears that a pokemon is only legendary when it is above 650 in total and most likely legendary from around 550-625.

Let's now check the correlation between gender and legendary status,
```{r}
pokemon$hasGender<-factor(pokemon$hasGender)
plot2<-ggplot(pokemon, aes(x =hasGender, fill = isLegendary)) + geom_bar()
plot2
```
As our first assumption suggested, the plot too suggests that majority of legendary pokemon (isLegendary = TRUE), do not have a gender (hasGender = FALSE). 

Let's see if there are any linear relationships within our Pokemon dataset. Name and Number will be excluded from examination as these will likely have no effect on the data. 

#Linear Model
Linear model, Total as response and HP, Attack, and Defense are predictors:
```{r}
library(DAAG)
linmod <- lm(poke.train$Total~poke.train$HP+poke.train$Attack+poke.train$Defense)
summary(linmod)
#plot(linmod)
plot(poke.train$HP+poke.train$Attack+poke.train$Defense, poke.train$Total)
abline(linmod, h = 0.5, col = "red")
#mmmm tasty sig values
predicted<-predict(linmod, newdata=poke.test)
mean(linmod$residuals^2)
mean((poke.test$Total-predicted)^2)
```


#Regression Tree, Total as response and HP, Attack, Defense, Sp_Atk, Sp_Def, and Speed as predictors
```{r}
library(tree)
poke<-data.frame(pokemon)
attach(poke)
pocl<-tree(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke)
plot(pocl)
text(pocl)
```

Let's try pruning back our tree from above,
```{r}
cv.pocl<-cv.tree(pocl, FUN=prune.tree)
plot(cv.pocl,type="b")
p.pocl<-prune.tree(pocl,best=10)
plot(p.pocl)
text(p.pocl)
summary(p.pocl)
```
We can see that the lowest is MSE is given with 12 nodes, suggesting that pruning may be unnecessary.

#Random Forests
Here is some bagging attempting to predict both Total and isLegendary
```{r}
library(randomForest)
set.seed(1995)
pokebag<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=6,importance=FALSE)
pokebag
pokebag2<-randomForest(isLegendary~ Total+hasGender,data=poke.train,mtry=6,importance=FALSE)
pokebag2
```

Random forest where m = 3
```{r}
pokeRF<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=3,importance=TRUE)
pokeRF
pokeRF2<-randomForest(isLegendary~Total+hasGender,data=poke.train,mtry=3,importance=TRUE)
pokeRF2
```
#Boosting
```{r}
poke <- data.frame(pokemon)
poke$isLegendary<-(as.integer(factor(poke$isLegendary))-1)
poke<-poke[,-c(1,2)]
set.seed(1995)
train<-sample(1:nrow(poke),432)
poke.test<-poke[-train,]
poke.train<-poke[train,]
library(glmnet)
 library(gbm)
 library(gclus)
```

## Boosting

Let's try using boosting on the pokemon data to predict if Legendary
```{r}
 set.seed(54390)
 pboost <- gbm(isLegendary~., distribution="bernoulli", data=poke, n.trees=5000, interaction.depth=1)
 table(poke$isLegendary, predict(pboost, newdata=poke, type="response", n.trees=5000)>0.5 )
 summary(pboost)
```


Splitting the data up into training and testing data....
```{r}
set.seed(54390)
pboost <- gbm(isLegendary~., distribution="bernoulli", data=poke.train, n.trees=5000, interaction.depth=1)
table(poke.test$isLegendary, predict(pboost, newdata=poke.test, type="response", n.trees=5000)>0.5 )
summary(pboost)
```

4 misclassifications... 
Looks like Total, Catch_Rate, Egg_Group1_1, and Pr_Male are the 4 most important variables in decreasing order.
it's interesting how hasGender is the second least important variable....

 
#KNN Classification

First we'll create testing and training sets and data frames with the predictors we're looking at on both sets, as well as a vector of responses.

```{r}
set.seed(1995)
train<-sample(1:nrow(pokemon),432)
poke.test<-pokemon[-train,]
poke.train<-pokemon[train,]
train.x<-cbind(HP,Attack,Defense,Sp_Atk,Sp_Def,Speed,Catch_Rate)[train,]
test.x<-cbind(HP,Attack,Defense,Sp_Atk,Sp_Def,Speed,Catch_Rate)[-train,]
train.legend<-isLegendary[train]
```

Now we'll run KNN on the testing data set using the training data and see how it does as a classifier.

```{r}
library(class)
library(MLmetrics)
knnLegend.pred<-knn(train.x,test.x,train.legend,k=5)
table(knnLegend.pred,poke.test$isLegendary)
F1_Score(poke.test$isLegendary,knnLegend.pred,positive="True")
```

Pretty great! Let's look at cross-validated error

```{r}
knnLegendCV<-knn.cv(cbind(HP,Attack,Defense,Sp_Atk,Sp_Def,Speed,Catch_Rate),pokemon$isLegendary,k=5,p=1)#,method="classification")
table(knnLegendCV,pokemon$isLegendary)
F1_Score(pokemon$isLegendary,knnLegendCV,positive="True")
```


#Linear Discriminant Analysis 
```{r}
library(MASS)
library(MLmetrics)
poke.train$hasGender<-factor(poke.train$hasGender)
poke.train$isLegendary<-factor(poke.train$isLegendary)
pokelda<-lda(poke.train$isLegendary~poke.train$hasGender+poke.train$Total)
table(poke.train$isLegendary, predict(pokelda)$class)
Sensitivity(poke.train$isLegendary, predict(pokelda)$class)
Recall(poke.train$isLegendary, predict(pokelda)$class) #same as sensitivity
Precision(poke.train$isLegendary, predict(pokelda)$class)
Specificity(poke.train$isLegendary, predict(pokelda)$class)
F1_Score(poke.train$isLegendary, predict(pokelda)$class)
```


```{r}
pokemon<-read.csv("pokemon_alopez247.csv")
poke <- data.frame(pokemon, stringsAsFactors = TRUE)
poke[is.na(poke)] <- 0
poke$isLegendary<-(as.integer(factor(poke$isLegendary))-1)
poke$hasGender<-(as.integer(factor(poke$hasGender))-1)
poke<-poke[,-c(1,2)]
set.seed(1995)
train<-sample(1:nrow(poke),432)
poke.train<-poke[train,]
poke.test<-poke[-train,]
```

##LDA 3
```{r}
pokemon<-read.csv("pokemon_alopez247.csv")
poke <- data.frame(pokemon, stringsAsFactors = TRUE)
poke[is.na(poke)] <- 0
poke$isLegendary<-(as.integer(factor(poke$isLegendary))-1)
poke$hasGender<-(as.integer(factor(poke$hasGender))-1)
poke<-poke[,-c(1,2)]
set.seed(1995)
train<-sample(1:nrow(poke),432)
poke.train<-poke[train,]
poke.test<-poke[-train,]
```

```{r}
#install.packages(MASS)
library(MASS)
```

```{r}
pkmlda<- lda(poke$isLegendary~poke$hasGender+poke$Pr_Male, data=poke, CV=TRUE)
table(poke$isLegendary, pkmlda$class)
```

```{r}
pkmlda<- lda(poke$isLegendary~poke$Type_1+poke$Type_2, data=poke, CV=TRUE)
table(poke$isLegendary, pkmlda$class)
```

```{r}
poke<-data.frame(pokemon)
```


#QDA
```{r}
pokeqda<-qda(poke.train$isLegendary~poke.train$hasGender+poke.train$Total)
table(poke.train$isLegendary, predict(pokeqda)$class)
Sensitivity(poke.train$isLegendary, predict(pokelda)$class)
Recall(poke.train$isLegendary, predict(pokeqda)$class) #same as sensitivity
Precision(poke.train$isLegendary, predict(pokeqda)$class)
Specificity(poke.train$isLegendary, predict(pokeqda)$class)
F1_Score(poke.train$isLegendary, predict(pokeqda)$class)
```

#Logistic Regression
```{r}
simlog<-glm(factor(poke.train$isLegendary)~poke.train$hasGender+poke.train$Total, family = "binomial")
table(predict(simlog, type = "response")>0.5, poke.train$isLegendary)
```

```{r}
pokemon<-read.csv("pokemon_alopez247.csv")
```

Turning all data into numerics

```{r}
poke<-data.frame(pokemon)
#remove unique identifiers
poke<-poke[,-c(1,2)]
```

```{r}
for(j in 1:ncol(poke)){
  if(!is.numeric(poke[,j]) ){
      poke[,j]<-(as.numeric(poke[,j]))
  }
}
poke$isLegendary <- (poke$isLegendary - 1)
poke$hasMegaEvolution <- (poke$hasMegaEvolution - 1)
poke$hasGender <- (poke$hasGender - 1)
```


## Logistic Regression

```{r}
library(class)
library(boot)
library("gclus")
# typeglm <- glm(poke.train$hasGender~poke.train$Type_1 + poke.train$Type_2, data=poke.train)
# typeglm
# predgend<- predict(typeglm, newdata = poke.test, type= "response")
# predgend
# predgend2<- predgend[c(1:289)]
# length(poke.test$hasGender)
# table(predgend2>0.5, poke.test$hasGender)
```
isLegendary ~ hasGender + Catch_Rate

```{r}
pokeglm<- glm(isLegendary ~ hasGender + Catch_Rate, family = "binomial", data = poke)
summary(pokeglm)
```

ok so the t test variable selection says all of the variables are important.
This might be Type 1 error??? (probs nah tbh why would a legendary pokemon need a gender or be easy to catch?)


Leave One Out Cross Validation!
```{r warning=FALSE}
attach(poke)
pokeglm <- list()
cv.mse <- NA
for(i in 1:nrow(poke)){
  cvisLeg <- poke$isLegendary[-i]
  cvhasGend <- poke$hasGender[-i]
  cvCatchR <- poke$Catch_Rate[-i]
  
  pokeglm[[i]]<- glm(cvisLeg ~ cvhasGend + cvCatchR, family = "binomial")
  cv.mse[i] <- (predict(pokeglm[[i]], newdata = data.frame(poke$isLegendary[i])) - poke$isLegendary[i])^2
  
}
mean(cv.mse)
```

MSE of 25.44115




<!-- #KNN classification for isLegendary -->

<!-- ```{r} -->
<!-- library(class) -->
<!-- knnrun<-knn.cv(pokeDist, cl = poke.train$isLegendary, k = 5, prob = TRUE) -->
<!-- table(poke.train$isLegendary, knnrun) -->
<!-- ``` -->

#Legends Per Generation and Legends per Type

```{r}
library(wesanderson)
#https://www.kaggle.com/excaliburzero/predicting-legendary-pokemon
poke<-data.frame(pokemon)
pokeLegend<-poke[which(poke$isLegendary=='True'),]
pokeLegend
plot(Generation~isLegendary)
TheLegends<-as.data.frame(table(pokeLegend$Generation))
colnames(TheLegends)<-c("Generation", "Legends")
TheLegends
summary(TheLegends)
plot<-ggplot(TheLegends, aes(Generation, Legends))+geom_bar(stat="identity", fill = wes_palette("Moonrise3", 6, type = "continuous")) 
plot
#color=scale_fill_manual(values=wes_palette("FantasticFox1"))
TheMan<-as.data.frame(table(pokeLegend$Type_1))
colnames(TheMan)<-c("Type 1", "Legends")
TheMan
summary(TheMan)
plot(TheMan)
maxTotalL<-order(TheMan$Legends, decreasing = TRUE)
head(TheMan[maxTotalL,])
#Of Type 2
TheMyth<-as.data.frame(table(pokeLegend$Type_2))
colnames(TheMyth)<-c("Type 2", "Legends")
TheMyth
summary(TheMyth)
plot(TheMyth)
maxTotalL2<-order(TheMyth$Legends, decreasing = TRUE)
head(TheMyth[maxTotalL2,])
```

```{r}
poke<-data.frame(pokemon)
poke1<-poke[which(hasGender=='True'),]
attach(poke)
head(poke1)
```

```{r}
set.seed(1995)
train<-sample(1:nrow(poke),432)
poke.test<-poke[-train,]
poke.train<-poke[train,]
```

#PCA for Legendary

Create PCA model

```{r}
poke<-data.frame(pokemon)
poke2<-poke[,c(6:11,20:22)]
head(poke)
pcapoke <- prcomp(as.matrix(poke2), scale=TRUE)
summary(pcapoke)
biplot(pcapoke)
```

Despite only accounting for 58% of the variance in the model, the Kaiser criterion would suggest keeping the first two principal components.

```{r}
round(pcapoke$rotation[,1:2], 2)
```

Looking at the first two principal components, the first has a high loading on most numeric stats. This may suggest that it can be used to predict isLegendary, let's run lda using PC1 as a predictor

##LDA on PC1

```{r}
poke[order(pcapoke$x[,1], decreasing=TRUE)[1:4] ,]
```

```{r}
poke[order(pcapoke$x[,2], decreasing=TRUE)[1:4] , 1:11]
```

The first component seems to refer to high stat, low catch rate Pokemon. Wait, let's see how many of them are legendary...

```{r}
poke[order(pcapoke$x[,1], decreasing=TRUE)[1:20],]
```


17 of the first 20 are legendary, this is a good sign. Let's see how PC1 correlates with isLegendary...

```{r}
library(MASS)
pcleg<-data.frame(pcapoke$x)
pcleg[1:20,]
leglda <- lda(factor(poke$isLegendary)~pcleg[,1])
leglda
table(poke$isLegendary,predict(leglda)$class)
F1_Score(poke$isLegendary,predict(leglda)$class,positive="True")
Recall(poke$isLegendary,predict(leglda)$class,positive="True")
```

So, it looks like PC1 does a decent job of classifying isLegendary, although the Recall is not great (i.e. it predicts False for isLegendary for a large number of trues).

##Classification trees on PCA

First, a simple tree

```{r}
library(tree)
pc<-data.frame(pcapoke$x)
pccl<-tree(poke$isLegendary~pc[,1]+pc[,2])
plot(pccl)
text(pccl)
summary(pccl)
table(predict(pccl,poke,type="class"),poke$isLegendary)
F1_Score(poke$isLegendary,predict(pccl,poke,type="class"),positive="True")
Recall(poke$isLegendary,predict(pccl,poke,type="class"),positive="True")
```

ALthough this model does relatively well on prediction, it seems needlessly complex, so we'll try pruning down.

```{r}
set.seed(13453)
cv.pccl<-cv.tree(pccl,FUN=prune.misclass)
plot(cv.pccl,type="b")
cv.pccl
```

Cross-validation suggests six terminal nodes does as well as the original ten, let's see.

```{r}
pr.pccl<-prune.misclass(pccl,best = 7)
plot(pr.pccl)
text(pr.pccl)
table(predict(pr.pccl,poke,type="class"),poke$isLegendary)
F1_Score(poke$isLegendary,predict(pr.pccl,poke,type="class"),positive="True")
Recall(poke$isLegendary,predict(pr.pccl,poke,type="class"),positive="True")
```

As predicted, six terminal nodes on the classification tree predict as well as ten.

Let's try bagging and random forests on the tree

```{r}
library(randomForest)
set.seed(1995)
pcbag<-randomForest(poke$isLegendary~pc[,1]+pc[,2],mtry=2,importance=TRUE)
pcbag
varImpPlot(pcbag)
table(poke$isLegendary,predict(pcbag,poke,type="class"))
pcbrec<-31/46
pcbrec
pcbprec<-662/677
pcbprec
pcbf1<-2*pcbrec*pcbprec/(pcbrec+pcbprec)
pcbf1
```

The bagged model performs worse, although because of the way the confusion matrix is calculated, it gives us a better idea at long run performance of the model (i.e. our cross-validated tree may be overfitting). Let's take a look at the random forest model.

```{r}
set.seed(1995)
pcrf<-randomForest(poke$isLegendary~pc[,1]+pc[,2],mtry=1,importance=TRUE)
pcrf
varImpPlot(pcrf)
pcbrec<-29/46
pcbrec
pcbprec<-662/679
pcbprec
pcbf1<-2*pcbrec*pcbprec/(pcbrec+pcbprec)
pcbf1
```

Very slightly better than bagging (which makes sense since we are only using two variables for classification). The variable importance plot gives almost no importance to PC2 for predicting isLegendary. Let's try classifying using only PC1 with some other models.


```{r}
library(MASS)
leglda <- lda(factor(poke$isLegendary)~pc[,1])
leglda
table(predict(leglda,poke)$class,poke$isLegendary)
```

LDA with only PC1 as a predictor clearly does not perform as well as PC2. Let's try out logistic regression.

```{r}
pc1log <- glm(factor(poke$isLegendary) ~ pc[,1] , family="binomial")
table(predict(pc1log, type="response") > .5, poke$isLegendary)
```

LogReg performs just as poorly as LDA. It seems that even though PC2 is not near as important as PC1 at predicting legendary status, it contains some crucial information that PC1 is missing.

#Neural Networks

<!--If there isLegendary stuff in here move it-->
```{r}
library(gclus)
library(nnet)
library(NeuralNetTools)
pokemon<-read.csv("pokemon_alopez247.csv")
set.seed(1995)
train<-sample(1:721,505)
trainset<-poke[train,]
testset<-poke[-train,]
spoke <- cbind(scale(trainset[,6:11]), factor(trainset$isLegendary))
colnames(spoke)[7] <- "isLegendary"
spoke<-data.frame(spoke)
nnpoke <- nnet(factor(isLegendary)~., data=spoke, size=5)
table(trainset$isLegendary, predict(nnpoke, type="class"))
plotnet(nnpoke)
```

```{r}
spoke
```

```{r}
spoketest <- cbind(scale(testset[,6:11]), factor(testset$isLegendary))
colnames(spoketest)[7] <- "isLegendary"
spoketest<-data.frame(spoketest)
table(spoketest$isLegendary, predict(nnpoke, newdata=spoketest, type="class"))
```

```{r}
trainsetg<-trainset[which(hasGender=='True'),]
testsetg<-testset[which(hasGender=='True'),]
trainsetg<-na.omit(trainsetg)
trainsetg
testsetg<-na.omit(testsetg)
testsetg
```

##LASSO

Let's try using LASSO to remove predictors from the linear model

```{r}
library(glmnet)
set.seed(53342)
pkmn<-data.frame(pokemon, stringsAsFactors = TRUE)
pkmn[is.na(pkmn)] <- 0
x <- data.matrix(pkmn)[,-13]
y <- as.integer(as.logical(pkmn$isLegendary))
grid<-exp(seq(-1.5,-8.25,length=100))
lassomod<-cv.glmnet(x,y, family = "binomial", alpha=1, lambda = grid)
plot(lassomod)
plot(lassomod$glmnet.fit, label=TRUE, xvar="lambda")
lammin <- lassomod$lambda.min
lam1se <- lassomod$lambda.1se
lasimmin <- glmnet(x,y,alpha = 1, lambda=lammin)
lasim1se <- glmnet(x,y,alpha = 1, lambda=lam1se)
#coef(lasimmin)
#coef(lasim1se)
```

Overall, the most important predictor is hasGender. This is not surprising and matches the rest of the analysis.
However, it is interesting and worth point out that after Pr_Male is removed, it becomes a more more promenent predictor. This is because Pr_Male is in many ways repeat data from hasGender. Any pokemon without a gernder has no probablity of being male. 

```{r}
pkmn<-data.frame(pokemon, stringsAsFactors = TRUE)
x <- data.matrix(pkmn)[,-c(15, 16)]
y <- as.integer(as.logical(pkmn$hasGender))
grid<-exp(seq(-2,-9,length=200))
lassomod<-cv.glmnet(x,y, family = "binomial", alpha=1, lambda = grid)
plot(lassomod)
plot(lassomod$glmnet.fit, label=TRUE, xvar="lambda")
lammin <- lassomod$lambda.min
lam1se <- lassomod$lambda.1se
lasimmin <- glmnet(x,y,alpha = 1, lambda=lammin)
lasim1se <- glmnet(x,y,alpha = 1, lambda=lam1se)
```
Removed $pokemon\$Pr\_Male$ bc is dependent on $pokemon\$hasGender$ and minimum was $\lim(LogLambda->-infinity)$.
```{r}
coef(lasimmin)
```
```{r}
coef(lasim1se)
```
Looks like $pokemon\$isLegendary$ is the most important variable...
```{r}
poke0<-data.frame(pokemon)
poke1<-poke0[which(poke0$hasGender=='True'),]
x <- data.matrix(poke1)[,-16]
y <- poke1$Pr_Male
grid<-exp(seq(-3,-8.5,length=150))
lassomod<-cv.glmnet(x,y, alpha=1, lambda = grid)
plot(lassomod)
plot(lassomod$glmnet.fit, label=TRUE, xvar="lambda")
lammin <- lassomod$lambda.min
lam1se <- lassomod$lambda.1se
lasimmin <- glmnet(x,y,alpha = 1, lambda=lammin)
lasim1se <- glmnet(x,y,alpha = 1, lambda=lam1se)
```
```{r}
coef(lasimmin)
```
```{r}
coef(lasim1se)
```
One thing to note is that this appears to have a large standard deviation.... The true minimum is at 19 variables but one standard deviation from that gives 8 variables.



####Fitting interactions
Reference:
https://strakaps.github.io/post/glinternet/

```{r}
#install.packages("glinternet")
library("glinternet")
```

```{r}
library(dplyr)
poke <- data.frame(pokemon)
y <- as.integer(as.logical(poke$isLegendary))
#1,2 are unique and not useful
poke <- poke[, -c(1,2, 13)]
# impute the median for the continuous variables
i_num <- sapply(poke, is.numeric)
poke[, i_num] <- apply(poke[, i_num], 2, function(x) ifelse(is.na(x), median(x, na.rm=T), x))
# impute empty categories
poke[, !i_num] <- apply(poke[, !i_num], 2, function(x) {
  x[x==""] <- "empty"
  x[is.na(x)] <- "missing"
  x
})
# get the numLevels vector containing the number of categories
X <- poke
X[, !i_num] <- apply(X[, !i_num], 2, factor) %>% as.data.frame()
numLevels <- X %>% sapply(nlevels)
numLevels[numLevels==0] <- 1
# make the categorical variables take integer values starting from 0
X[, !i_num] <- apply(X[, !i_num], 2, function(col) as.integer(as.factor(col)) - 1)

```


```{r}
cv_fit <- glinternet.cv(X, y, numLevels)
plot(cv_fit)
```

```{r}
i_1Std <- which(cv_fit$lambdaHat1Std == cv_fit$lambda)
coefs <- coef(cv_fit$glinternetFit)[[i_1Std]]
coefs
```

####Main Effects (part without interactions)

```{r}
coefs$mainEffects
idx_num <- (1:length(i_num))[i_num]
idx_cat <- (1:length(i_num))[!i_num]
names(numLevels)[idx_cat[coefs$mainEffects$cat]]
names(numLevels)[idx_num[coefs$mainEffects$cont]]
coefs$mainEffectsCoef
```

Main Effects are Total, Sp_Atk, Sp_Def, and Weight

####Interactions
```{r}
coefs$interactions
```

The $catcat tells us that there is no interaction between the categorical variables

Three pairs of continuous variables have interactions:  
$(1,5)$, $(1,6)$, and $(1,11)$
Total interacts with Sp_Atk, Sp_Def, and Catch_Rate, which is interesting.

```{r}
coefs$interactionsCoef$contcont
```

There is one interaction between categorical and continuous variables:
Sp_Atk and Type_1
```{r}
coefs$interactionsCoef$catcont
```

####MSE
```{r}
sqrt(cv_fit$cvErr[[i_1Std]])
```
MSE of 0.09163895

#Gender Analyses

Let's see if there is a relationshp between Score and Pr_Male, a predictor for the probability of gender according to male
```{r}
poke1<-pokemon[which(hasGender=='True'),]
poke1
set.seed(983457)
pokeG<-tree(Pr_Male~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed + Total,data=poke1)
plot(pokeG)
text(pokeG, pretty=0)
cv.pokeG<-cv.tree(pokeG, FUN=prune.tree)
plot(cv.pokeG)
prunePokeG<-prune.tree(pokeG, best=12)
plot(prunePokeG)
text(prunePokeG, pretty=0)
```


##Trees on the new data set

Let's look at predicting Pr_Male using the numeric stats:

```{r}
attach(poke1)
library(tree)
pocl<-tree(Pr_Male~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed+Height_m+Weight_kg+Catch_Rate,data=poke1)
plot(pocl)
text(pocl)
mean((poke1$Pr_Male-predict(pocl))^2)
```

Ok, let's prune this tree down now... (note the for loop is used because the best number of terminal nodes varied depending on the seed)

```{r}
j<-sample(0,10000,100)
size<-{}
for(i in 1:100) {
  set.seed(i)
  cv.pocl<-cv.tree(pocl, FUN=prune.tree)
  size[i]<-cv.pocl$size[which.min(cv.pocl$dev)]
}
data.frame(table(size))
```

Now we'll take a look at a tree pruned down to two terminal nodes.

```{r}
p.pocl<-prune.tree(pocl,best=2)
plot(p.pocl)
text(p.pocl)
summary(p.pocl)
mean((poke1$Pr_Male-predict(p.pocl))^2)
```

That doesn't explain much, so let's take a look at four terminal nodes instead.

```{r}
p.pocl<-prune.tree(pocl,best=4)
plot(p.pocl)
text(p.pocl)
summary(p.pocl)
mean((poke1$Pr_Male-predict(p.pocl))^2)
```

Alright, let's use bagging now...

```{r}
library(randomForest)
set.seed(1995)
pokebag<-randomForest(Pr_Male~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed+Height_m+Weight_kg+Catch_Rate,data=poke1,mtry=9,importance=TRUE)
pokebag
varImpPlot(pokebag)
mean((poke1$Pr_Male-predict(pokebag))^2)
```

Well that didn't work out very well...

How about random forest...

```{r}
pokeRF<-randomForest(Pr_Male~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed+Height_m+Weight_kg+Catch_Rate,data=poke1,mtry=1,importance=TRUE)
pokeRF
varImpPlot(pokeRF)
mean((poke1$Pr_Male-predict(pokeRF))^2)
```

Very slightly better, still not a lot of evidence that this model is any good.

Let's see what the tree looks like when we cut out the least important predictors.

```{r}
poketree<-tree(Pr_Male~Attack+Defense+Height_m+Weight_kg+Catch_Rate,data=poke1)
plot(pocl)
text(pocl)
mean((poke1$Pr_Male-predict(poketree))^2)
```

Ok, let's prune this tree down now...

```{r}
j<-sample(0,10000,100)
size<-{}
for(i in 1:100) {
  set.seed(i)
  cv.poketree<-cv.tree(poketree, FUN=prune.tree)
  size[i]<-cv.poketree$size[which.min(cv.poketree$dev)]
}
data.frame(table(size))
```

Tree pruned down to four terminal nodes.

```{r}
p.poketree<-prune.tree(pocl,best=4)
plot(p.poketree)
text(p.poketree)
summary(p.poketree)
mean((poke1$Pr_Male-predict(p.poketree))^2)
```

Alright, let's use bagging now...

```{r}
library(randomForest)
set.seed(1995)
poketbag<-randomForest(Pr_Male~Attack+Defense+Height_m+Weight_kg+Catch_Rate,data=poke1,mtry=5,importance=TRUE)
poketbag
varImpPlot(poketbag)
mean((poke1$Pr_Male-predict(poketbag))^2)
```

How about random forest...

```{r}
poketRF<-randomForest(Pr_Male~Attack+Defense+Height_m+Weight_kg+Catch_Rate,data=poke1,mtry=1,importance=TRUE)
poketRF
varImpPlot(poketRF)
mean((poke1$Pr_Male-predict(poketRF))^2)
```

These models performed worse than if we kept all the numerical predictors.

##KNN
```{r}
poke<-data.frame(pokemon)
#remove unique identifiers
poke<-poke[,-c(1,2)]
```
This block removes all NA values for Pr_Male.
```{r}
#the new dataset poke2 has all na values fr Pr_Male removed
poke2<-poke[which(hasGender=='True'),]
poke2
```
```{r}
for(j in 1:ncol(poke2)){
  if(!is.numeric(poke2[,j]) ){
      poke2[,j]<-(as.numeric(poke2[,j]))
  }
}
poke2$isLegendary <- (poke2$isLegendary - 1)
poke2$hasMegaEvolution <- (poke2$hasMegaEvolution - 1)
poke2$hasGender <- (poke2$hasGender - 1)
```

```{r}
poke<-data.frame(pokemon)
#remove unique identifiers
poke<-poke[,-c(1,2)]
```

```{r}
for(j in 1:ncol(poke)){
  if(!is.numeric(poke[,j]) ){
      poke[,j]<-(as.numeric(poke[,j]))
  }
}
poke$isLegendary <- (poke$isLegendary - 1)
poke$hasMegaEvolution <- (poke$hasMegaEvolution - 1)
poke$hasGender <- (poke$hasGender - 1)
```

##KNN

```{r}
poke<-data.frame(pokemon)
#remove unique identifiers
poke<-poke[,-c(1,2)]
```

Note that KNN requires numerics, not factors. first we must remove them

```{r}
#the new dataset poke2 has all na values fr Pr_Male removed
poke2<-poke[which(hasGender=='True'),]
poke2
```


```{r}
for(j in 1:ncol(poke2)){
  if(!is.numeric(poke2[,j]) ){
      poke2[,j]<-(as.numeric(poke2[,j]))
  }
}
poke2$isLegendary <- (poke2$isLegendary - 1)
poke2$hasMegaEvolution <- (poke2$hasMegaEvolution - 1)
poke2$hasGender <- (poke2$hasGender - 1)
```

on to the regression!

```{r}
library(ggplot2)
library(FNN)
poke3<-data.frame(poke2[,-c(2, 14, 16)])
plot(poke2$Pr_Male, type ="p")
knnr20 <- knn.reg(poke2[,-c(2, 14, 16)], y=poke2$Pr_Male, k = 20)
lines(knnr20$pred, col="green", lwd=1)
```
knnreg by default returns cross validated results
```{r}
knnr20$R2Pred
knnr20$PRESS
```

```{r}
mse<-NA
for(i in 1:nrow(poke2)){
  mse[i]<- (poke2$Pr_Male[i] - knnr20$pred[i])^2
}
mean(mse)
```


```{r}
poke4<-poke[which(hasGender=='True'),]
poke4<-data.frame(poke4[-c(2,14,16)])
name<-list("Type_1", "Total", "HP", "Attack", "Defense", "Sp_Atk", "Sp_Def", "Speed", "Generation", "isLegendary", "Colour", "hasGender", "Egg_Group_1", "hasMegaEvolution", "Height_m", "Weight_kg", "Catch_Rate", "Body_Style")
for(j in 1:ncol(poke3)){
  plot(poke2$Pr_Male~poke4[,j], xlab = name[j])
  lines(knnr20$pred, col="green", lwd=1)
}
```
Using k = 30
```{r}
library(ggplot2)
library(FNN)
poke3<-data.frame(poke2[,-c(2, 14, 16)])
plot(poke2$Pr_Male, type ="p")
knnr30 <- knn.reg(poke2[,-c(2, 14, 16)], y=poke2$Pr_Male, k = 30)
lines(knnr30$pred, col="blueviolet", lwd=1)
```

```{r}
knnr30$R2Pred
knnr30$PRESS
```

```{r}
mse<-NA
for(i in 1:nrow(poke2)){
  mse[i]<- (poke2$Pr_Male[i] - knnr30$pred[i])^2
}
mean(mse)
```
looks like it works better than k=20


#Graph with Pr_Male

```{r}
head(poke1)
countM<-0
maleProb<-vector()
countF<-0
femaleP<-vector()
fifty<-0
splitP<-vector()
for(i in 1:nrow(poke1)){
  if(poke1[i,16]>0.5){
    countM<-countM + 1
    maleProb<-c(maleProb, poke[i,16])
  }
  if(poke1[i,16]==0.5){
    fifty<-fifty + 1
    splitP<-c(splitP, poke[i,16])
  }
  if(poke1[i,16]<0.5){
    countF<-countF+1
    femaleP<-c(femaleP, poke[i,16])
  }
}
vect<-cbind(countM, fifty, countF)
vect
library(wesanderson)
sp<-ggplot(poke1, aes(poke1$Pr_Male, fill = poke1$Pr_Male)) + geom_histogram(stat="count", color = "black", fill = wes_palette("FantasticFox1", 7, type = "continuous")) 
sp
```
##Plot on Pr_Male over Generations

```{r}
poke<-data.frame(pokemon)
```

```{r}
library(ggplot2)
pokedat<-poke[which(poke$hasGender=='True'),]
pokedat <- pokedat[,c(12,16)]
ggplot(pokedat)+
  geom_point(aes(pokedat$Generation, pokedat$Pr_Male))
library(plyr)
mu <- ddply(pokedat, "Generation", summarise, grp.mean=mean(Pr_Male))
head(mu)
colors = c("1","2","3","4","5","6")
ggplot(pokedat, aes(x=pokedat$Pr_Male, group=pokedat$Generation, fill=colors[Generation]))+
  geom_histogram(position="dodge",binwidth=0.25)+theme_bw()
```
<!-- See what a regression tree looks like using total as the predictor and hp, attack, defense, sp_atk, sp_def, and speed as predictors. -->
<!-- ```{r} -->
<!-- pokemon<-read.csv("pokemon_alopez247.csv") -->
<!-- library(tree) -->
<!-- poke<-data.frame(pokemon) -->
<!-- attach(poke) -->
<!-- pocl<-tree(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke) -->
<!-- plot(pocl) -->
<!-- text(pocl) -->
<!-- ``` -->

<!-- Now let's try pruning it back -->

<!-- ```{r} -->
<!-- cv.pocl<-cv.tree(pocl, FUN=prune.tree) -->
<!-- plot(cv.pocl,type="b") -->
<!-- p.pocl<-prune.tree(pocl,best=10) -->
<!-- plot(p.pocl) -->
<!-- text(p.pocl) -->
<!-- summary(p.pocl) -->
<!-- ``` -->

<!-- Looks like pruning was unnecessary since the lowest MSE is with 12 nodes... -->

<!-- How about with bagging... -->

<!-- ```{r} -->
<!-- library(randomForest) -->
<!-- set.seed(1995) -->
<!-- pokebag<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=6,importance=FALSE) -->
<!-- pokebag -->
<!-- ``` -->
<!-- Random forest where m=3 -->
<!-- ```{r} -->
<!-- pokeRF<-randomForest(Total~HP+Attack+Defense+Sp_Atk+Sp_Def+Speed,data=poke,mtry=3,importance=TRUE) -->
<!-- pokeRF -->
<!-- ``` -->



##PCA

Alright, let's check out PCA on Pr_Male response with ...stats as predictors

```{r}
head(poke)
```

```{r}
pcapoke <- prcomp(as.matrix(poke[,6:11]), scale.=TRUE)
summary(pcapoke)
biplot(pcapoke)
```

Ok cool, two principal components satisfy the Kaiser criterion. Let's take a look at which predictors influence these components...

```{r}
round(pcapoke$rotation[,1:2], 2)
```

Ok, so looks like PC1 refers to kind of all around, balanced pokemon, and PC2 refers to slow defenders with bad HP? I don't think this model is all that great... But, let's see which pokemon each component is referring to.

```{r}
poke[order(pcapoke$x[,1], decreasing=TRUE)[1:4] , 1:11]
```

```{r}
poke[order(pcapoke$x[,2], decreasing=TRUE)[1:4] , 1:11]
```

The first component doesn't really seem to refer to much at all, just kind of all around generalists maybe. The totals are quite high though, so maybe these are the powerhouses? Wait, let's see how many of them are legendary...

```{r}
poke[order(pcapoke$x[,1], decreasing=TRUE)[1:20],]
```


The first 13 are legendary, this is a good sign. Let's see how PC1 correlates with isLegendary...

```{r}
library(MASS)
pcleg<-data.frame(pcapoke$x)
pcleg[1:20,]
leglda <- lda(factor(poke$isLegendary)~pcleg[,1])
leglda
table(poke$isLegendary,predict(leglda)$class)
F1_Score(poke$isLegendary, predict(leglda)$class)
```

OK, so using LDA with PC1 as a predictor is a pretty great model for predicting isLegendary!


##Gender PCA

Ok, now let's run PCA on the subset that has a gender

```{r}
pcagenpoke <- prcomp(as.matrix(poke1[,6:11]), scale.=TRUE)
summary(pcagenpoke)
biplot(pcagenpoke)
```

Ok cool, two principal components satisfy the Kaiser criterion. Let's take a look at which predictors influence these components...

```{r}
round(pcagenpoke$rotation[,1:2], 2)
```
This is looking pretty similar to the full dataset! But, let's see which pokemon each component is referring to.

```{r}
poke[order(pcagenpoke$x[,1], decreasing=TRUE)[1:4] , 1:11]
```


```{r}
poke[order(pcagenpoke$x[,2], decreasing=TRUE)[1:4] , 1:11]
```

The first component doesn't really seem to refer to much at all, just kind of all around generalists maybe. The totals are quite high though, so maybe these are the powerhouses? Wait, let's see how many of them are legendary...

```{r}
poke[order(pcagenpoke$x[,1], decreasing=TRUE)[1:20],]
```


The first 13 are legendary, this is a good sign. Let's see how PC1 correlates with isLegendary...

```{r}
library(MASS)
pcgenleg<-data.frame(pcagenpoke$x)
pcgenleg[1:20,]
leggenlda <- lda(factor(poke1$isLegendary)~pcgenleg[,1]+pcgenleg[,2],data=pcgenleg)
leggenlda
```

Ok now let's look at a classification table:

```{r}
lda.pred<-predict(leggenlda,poke1)
lda.class<-lda.pred$class
table(lda.class,poke1$isLegendary)
```

So LDA using PC1 and PC2 basically amounts to a naive classifier classifying everything "False" for isLegendary. Let's see if univariate LDA with PC1 only does any better.

```{r}
leggenlda1 <- lda(factor(poke1$isLegendary)~pcgenleg[,1],data=pcgenleg)
leggenlda1
```

```{r}
lda.pred<-predict(leggenlda1,poke1)
lda.class<-lda.pred$class
table(lda.class,poke1$isLegendary)
```

Yea, this is still a naive classifier, NOT VERY USEFUL!

Let's try a linear model, see if PC1 and PC2 are any good at predicting Pr_Male:

```{r}
linmod<-lm(poke1$Pr_Male~pcgenleg[,1]+pcgenleg[,2])
summary(linmod)
linmod<-lm(poke1$Pr_Male~pcgenleg[,1])
summary(linmod)
plot(pcgenleg[,1],poke1$Pr_Male)
abline(linmod)
```

Ok, so the second model is statistically significant. So let's try to interpret this now. The intercept on this linear model is 0.55, which is already above 50%. Oh man that graph looks like garbage. I don't think PCA really did anything here...


```{r}
# linmod<-lm(poke1$Catch_Rate~pcgenleg[,1]+pcgenleg[,2])
# summary(linmod)
linmod<-lm(poke1$Catch_Rate~pcgenleg[,1])
summary(linmod)
plot(pcgenleg[,1],poke1$Catch_Rate)
abline(linmod)
```

Ok, now we're talking. So it looks like PC1 is correlated with the harder to catch Pokemon rather than the legendary ones. Probably a good time to start a new file, this is getting messy...



##LASSO with interactions with hasGender Removed on Total

```{r}
#install.packages("glinternet")
library("glinternet")
library(dplyr)
```

```{r}
poke <- data.frame(pokemon)
poke<-poke[which(poke$hasGender=='True'),]
y <- as.integer(poke$Total)
#1,2 are unique and not useful
#removed hasGender
#using total as response
poke <- poke[, -c(1,2, 5, 15)]
poke
# impute the median for the continuous variables
i_num <- sapply(poke, is.numeric)
poke[, i_num] <- apply(poke[, i_num], 2, function(x) ifelse(is.na(x), median(x, na.rm=T), x))
# impute empty categories
poke[, !i_num] <- apply(poke[, !i_num], 2, function(x) {
  x[x==""] <- "empty"
  x[is.na(x)] <- "missing"
  x
})
# get the numLevels vector containing the number of categories
X <- poke
X[, !i_num] <- apply(X[, !i_num], 2, factor) %>% as.data.frame()
numLevels <- X %>% sapply(nlevels)
numLevels[numLevels==0] <- 1
# make the categorical variables take integer values starting from 0
X[, !i_num] <- apply(X[, !i_num], 2, function(col) as.integer(as.factor(col)) - 1)

```


```{r}
cv_fit <- glinternet.cv(X, y, numLevels)
#plot(cv_fit)
```

```{r}
i_1Std <- which(cv_fit$lambdaHat1Std == cv_fit$lambda)
coefs <- coef(cv_fit$glinternetFit)[[i_1Std]]
coefs
```

####Main Effects (part without interactions)

```{r}
coefs$mainEffects
idx_num <- (1:length(i_num))[i_num]
idx_cat <- (1:length(i_num))[!i_num]
names(numLevels)[idx_cat[coefs$mainEffects$cat]]
names(numLevels)[idx_num[coefs$mainEffects$cont]]
coefs$mainEffectsCoef
```

Main Effects are "HP", "Attack", "Defense", "Sp_Atk", "Sp_Def", "Speed", and "Catch_Rate"

####Interactions
```{r}
coefs$interactions
```

There are no significant interactions

####MSE
```{r}
sqrt(cv_fit$cvErr[[i_1Std]])
```
MSE of 0.812088



##LASSO with interactions on Pr_Male

```{r}
#install.packages("glinternet")
library("glinternet")
library(dplyr)
```

```{r}
poke <- data.frame(pokemon)
poke<-poke[which(poke$hasGender=='True'),]
y <- as.integer(poke$Pr_Male)
#1,2 are unique and not useful
#using prmale as response
poke <- poke[, -c(1,2, 16)]
poke
# impute the median for the continuous variables
i_num <- sapply(poke, is.numeric)
poke[, i_num] <- apply(poke[, i_num], 2, function(x) ifelse(is.na(x), median(x, na.rm=T), x))
# impute empty categories
poke[, !i_num] <- apply(poke[, !i_num], 2, function(x) {
  x[x==""] <- "empty"
  x[is.na(x)] <- "missing"
  x
})
# get the numLevels vector containing the number of categories
X <- poke
X[, !i_num] <- apply(X[, !i_num], 2, factor) %>% as.data.frame()
numLevels <- X %>% sapply(nlevels)
numLevels[numLevels==0] <- 1
# make the categorical variables take integer values starting from 0
X[, !i_num] <- apply(X[, !i_num], 2, function(col) as.integer(as.factor(col)) - 1)

```


```{r}
cv_fit <- glinternet.cv(X, y, numLevels)
#plot(cv_fit)
```

```{r}
i_1Std <- which(cv_fit$lambdaHat1Std == cv_fit$lambda)
coefs <- coef(cv_fit$glinternetFit)[[i_1Std]]
```

####Main Effects (part without interactions)

```{r}
coefs$mainEffects
```

```{r}
idx_num <- (1:length(i_num))[i_num]
idx_cat <- (1:length(i_num))[!i_num]
names(numLevels)[idx_cat[coefs$mainEffects$cat]]
names(numLevels)[idx_num[coefs$mainEffects$cont]]
coefs$mainEffectsCoef
```


####Interactions
```{r}
coefs$interactions
```


####MSE
```{r}
sqrt(cv_fit$cvErr[[i_1Std]])
```
MSE of 0.812088


##Neural Net predicting Pr_Male
```{r}
attach(data)
trainsetg<-trainset[which(hasGender=='True'),]
testsetg<-testset[which(hasGender=='True'),]
trainsetg<-na.omit(trainsetg)
trainsetg
testsetg<-na.omit(testsetg)
testsetg
```

```{r}
set.seed(906534)
library(neuralnet)
library(gclus)
library(nnet)
library(NeuralNetTools)
nnmale <- neuralnet(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed + Catch_Rate + Weight_kg +Height_m,data=trainsetg, hidden=5, threshold=0.01)
plotnet(nnmale)
mse<-mean((compute(nnmale, testsetg[,c(6:11, 20:22)])$net.result-testsetg$Pr_Male)^2)
mse
```


```{r}
linmod<-lm(Pr_Male ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed + Catch_Rate + Weight_kg +Height_m,data=trainsetg)
mean((predict(linmod,newdata=testsetg)-testsetg$Pr_Male)^2)
```
This is pretty close to our neural net modeled above when we use 1 hidden layer and 3 nodes. 

##Neural net predicting hasGender
```{r}
library(gclus)
library(nnet)
library(NeuralNetTools)
set.seed(1995)
gpoke <- cbind(scale(trainset[,c(6:11, 20:22)]), factor(trainset$hasGender))
colnames(gpoke)[10] <- "hasGender"
gpoke<-data.frame(gpoke)
nngend <- nnet(factor(hasGender)~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed + Catch_Rate + Height_m + Weight_kg, data=gpoke, size=)
plotnet(nngend)
table(trainset$hasGender, predict(nngend, type="class"))
```
It appears that our neural net is effective in predicting hasGender, and also easy to generate an overfitted model for. 
1 hidden layer with 11 nodes appears to overfit the model, 

  
Instead 1 hidden layer with 4 nodes appears to have a reasonable misclassification without totally overfitting. Let's try this on gspoketest,

```{r}
gpoketest <- cbind(scale(testset[,c(6:11, 20:22)]), factor(testset$hasGender))
colnames(gpoketest)[10] <- "hasGender"
gpoketest<-data.frame(gpoketest)
table(gpoketest$hasGender, predict(nngend, newdata=gpoketest, type="class"))
```

It appears then that the optimal amount of nodes for our neural network is equal to 4 within 1 hidden layer. We can see that our misclassification for our gpoketest is relatively okay, and appears to be the best balance when we tune our network to 4 nodes. 
It should not come as a surprise that hasGender is easily modeled with a neural net from the stat predictors provided. Given that the better the stats, the more likely the Pokemon is to be of the legendary type, and thus too likely not to have a gender. Our neural nets ability to predict gender based on the Pokemon's stats confirms that the higher or "better" the stats, the more likely the Pokemon is to not have a gender. 

##Neural net predicting Generation
```{r}
library(gclus)
library(nnet)
library(neuralnet)
library(NeuralNetTools)
set.seed(19127395)
#nnGeneration <- neuralnet(Generation ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed + Pr_Male,data=trainsetg, hidden=5, threshold=0.01)
nnGeneration <- neuralnet(Generation ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg, hidden=4, threshold=0.01)
plotnet(nnGeneration)
mse<-mean((compute(nnGeneration, testsetg[,6:11])$net.result-testsetg$Generation)^2)
mse
```

```{r}
set.seed(19127395)
linmod<-lm(Generation ~ Attack + Defense + HP + Sp_Atk + Sp_Def + Speed,data=trainsetg)
mean((predict(linmod,newdata=testsetg)-testsetg$Generation)^2)
```


#Mixture Modeling
Predictors 6-10 (Attack, Defense, Sp_Atk, Sp_Def) used in generating clPairs and mclust
```{r}
library(mclust)
clPairs(pokemon[c(6:10, 20:21)], cl = pokemon$Total)
clp <- clPairs(pokemon[c(6:8, 20:21)], cl = pokemon$Total, lower.panel = NULL)
clPairsLegend(0.1, 0.4, class = clp$class, 
              col = clp$col, pch = clp$pch, 
              title = "Pokemon Type_1")
#https://www.rdocumentation.org/packages/mclust/versions/5.4.3/topics/clPairs
```

These do not appear to help all too much, let's try using the teigen and mclust functions,

##mclust without scaling
```{r}
library(teigen)
library(mclust)
pokeMix <- teigen(pokemon[,c(6:10, 20:21)], Gs=1:5, model="UCCU", scale=FALSE, verbose=FALSE)
plot(pokeMix, xmarg=1, what="contour")
plot(pokeMix, xmarg=1, what="uncertainty")
mrun <- Mclust(pokemon[,c(6:10, 20:21)], G=1:5) 
t(mrun$BIC)
```

Based on the BIC criterion on the unscaled mclust, we see that there are 4-5 suggested groups, primairly suggestsing 5 groups within the VVV model. Our marginal and uncertainty plot on the otherhand report 4 groups, with what appears a significant amount of uncertainty of group membership. When the data is scaled, we do appear to get 5 groups of the VVV model as above. 

##Scaled mclust 
```{r}
library(mclust)
mruns <- Mclust(scale(pokemon[c(6:10, 20:21)]), G=1:5) 
#mruns <- Mclust(scale(pokemon[c(6:10, 20:21)]), G=1:5) 
#Fitted with weight and height predictors
t(mruns$BIC)
```

It may be reasonable to suggest that using mclust on the Pokemon data set may not be a sufficient model for the data, as it contains a large amount of categorical data. While KNN testing suggested 5 potential groups, the model used categorical data. It may be that the Pokemon dataset contains such a large diversity of typing, that mclust cannot accurately predict group membership since the dataset does not subscribe to such membership in the first place. At least not in such a way where group membership can be determined by Pokemon stats such as HP, Attack, Defense, Weight_kg, or Height_m. 
5 groups may be than considered an inaccurate representation of the Pokemon dataset. 

```{r}
mrun5 <- Mclust(pokemon[c(6:8, 20:21)], 5)
#table(pokemon$Egg_Group_1, mrun5$classification)
plot(pokemon[c(16:18,20)], col=mrun5$classification)
adjustedRandIndex(pokemon$Height_m, mrun5$classification)
```

From the plot above it appears that possibly height may be related to the groupings, however when we run adjustedRandIndex, we see a value of 0.08019253 that indicates low aggreement. It is worth noting that Height_m is a continuous variable, which may pose the seperate issue of evaluating agreement with the adjusted random index using Weight_m. Overall, it appears that Mclust and adjustedRandIndex is not particularly useful in better understanding our data, and may paint an inaccurate representation of groups that cannot be confirmed nor denied through use of the  Mclust and adjustedRandIndex functions. 
